\chapter{Encoding E-graphs in Existing Datalog Systems}\label{chapter/datalog}

% \section{Introduction}

In \autoref{chapter/nonrel-em},
 we discussed optimizations to make classical \ematching faster. 
As we see, there are still many limitations to the classical \ematching algorithm
 despite the proposed optimizations.
Query plans are limited to certain special forms,
 so many queries are asymptotically slower using classical \ematching.
Moreover,
 many advanced join algorithms (like the generic join algorithm) 
 and optimizations (like ones using cardinality estimation) cannot be used
 due to the fundamental restriction of its graph representation.
To enjoy the highly efficient \ematching procedure and the provided theoretical guarantees,
 we have to look back at the relational \ematching approach.
However,
 relational \ematching has the ``dual representation'' problem:
While \ematching is performed on the relaitonal representation,
 the graph representation is necessarily for standard \egraph operations
 like congruence maintenance.
Therefore,
 both representations are needed and should be kept in sync
 for relational \ematching to work.
This can have nontrivial overheads \citep{relational-ematching}.

A natural question to ask is, 
 if keeping both representation is expensive, 
 and efficient \ematching requires a relational representation,
 can we keep only the relational representation?
This way, 
 we are doing not only \ematching relationally,
 but also all other \egraph operations,
 and the ultimate goal is to be able to run equality saturation
 in this relational representation.
Compared to the optimizations described in \autoref{chapter/nonrel-em},
 this proposal is more radical,
 as it challenges the well-accepted assumption that an e-\textit{egraph} is a graph.
To implement this proposal, two key issues need to be addressed.
First,
 equality saturation uses equational rewrites to grow the \egraph,
 so it is important to understand the semantics of rewrites 
 in the relational representation.
Second,
 a key ingredient to \egraphs is the maintenance of its congruence invariant.
Therefore,
 a relational \egraph must be able to perform congruence maintenance as well.
To address the first issue, 
 we propose to encode \egraphs in Datalog.
Datalog is a relational language with rigourous semantics and efficient evaluation algorithms,
 where logic rules describe dependencies between relations.
Logic rules in Datalog have the form $R(\ldots) :- R1(\ldots),\ldots,Rn(\ldots)$ and
 operationally performs fixpoint-based rewrites but for relations.
Moreover, both rewrites in \egraphs and logics rules in Datalog are non-destructive,
 meaning that they do not remove original facts during the rewrites.
Therefore,
 it is tempting to encode \egraph rewrites in Datalog.

This chapter introduces my experience encoding \egraph rewrites 
 in two Datalog systems, namely Souffl\'e \citep{souffle} and Rel \citep{rel-doc}.
Souffl\'e and Rel are different in many aspects, with different targeted use cases:
 Souffl\'e focuses on applications like program analyses
 and has a semantics very similar to the original Datalog,
 with ``mild'' extensions like algebraic data types (ADTs),
 built-in support for equivalence relations, and the choice operator.
One of the most aggressive extension is perhaps
 the newly added subsumption,
 which allows the users to delete tuples 
 when it is clear that they are subsumed by other more general tuples \citep{datalog-subsumption}.
We will see subsumption is in fact critical in preventing the encoded \egraphs from blowup.
Rel, in contrast, has more ambitious goals.
While spiritually inspired by Datalog, 
 Rel has a much more expressive front end language based on first-order logic.
As an example, 
 queries in Rel support universal quantifiers and existential quantifiers in arbitrary positions
 (as long as the domain of the quantified variables are finitely enumerable).

One important distinction between Souffl\'e and Rel is
 that Rel supports recursive aggregates out of box.
Rigourous theories are developed 
 for sound programming with recursive aggregates in Rel \citep{datalogo-convergence},
 yet to facilitate even more flexible general-purpose programming,
 soundness are not enforced in practice.
As a result,
 one needs to be careful when using recursive aggregates in Rel,
 to not violate properties like monotonicity.
I use recursive aggregates in both encodings:
 while Rel supports it out of box, 
 for Souffl\'e, I explicitly disabled the stratification checker.
Despite the wide use of recursive aggregates, the encoding is still sound,
 because it is semantically clear that rewrites in an \egraph is monotonic.
Moreover, in the encoding,
 tuples are only removed when they are subsumed by a more canonicalized version of them,
 which intuitively provides a justification for the soundness.

A key ingredient to making \egraph efficient is 
 to keep only the canonical tuples.
However, the encoding in both systems are not completely satisfying.
For Souffl\'e with the subsumption extension,
 a tuple can only be removed when it is able to find an evidence 
 that this tuple is subsumed.
For Rel, every iteration starts from scratch,
 so the only way to remove tuples is 
 to recompute all the facts in the current iteration while excluding the removed tuples,
 which is indirect.
Despite demonostrating the feasibility of encoding \egraphs in Datalog, 
 both encodings are practically orders-of-magnititude slower than \egg.
Constraint-Handlign Rules (CHR) \citep{chr} is a potential solution to this problem,
 as its rules allows more flexible removal of tuples.
Moreover,
 the literature has investigated 
 ways to encode the optimal implementation of union-find in CHR \citep{uf-chr},
 which is perhaps the most critical step in encoding an \egraph.
However, I did not pursue this approach for a long time, 
 since as far as I am aware, available implementations of CHR either misses important features,
 or is obsure and difficult to use.

Through out this chapter, we will use a very classical equality saturation program,
 namely associativity and commutativity (AC rules) of the $+$ operator, as our example.
The (pseudo)code in \autoref{fig:eqsat-example} shows how this can be defined in a library like \egg.
As a baseline, it takes less than one second for \egg to conclude that
 $\sum_{i=1}^{8}v_i$ is in the same \eclass as $\sum_{i=8}^{1}v_i$.
For our Datalog encoding,
 we did not expect it to be as efficient as highly specialized \egraph frameworks like \egg.
In fact, even the best encodings presented in this chapter
 are not capable of proving the above equivalence,
 although it is not unimaginable that a customized Datalog engine can be specialized
 for our \egraph encodings and therefore more efficient.
Moreover,
 for each of our encodings,
 it is either the case that there are more or less overheads 
 that will not been seen in a sensible \egraph impelementation,
 or we have to do some delicate hacking into the Datalog engine that 
 the engine impelementers may be surprised about.
Therefore, in some sense,
 our attempts to encode \egraphs in Datalog is unsatisfactory.
However, 
 as we will see,
 there are many shining gems we find during this journey.

\begin{lstlisting}[
    label=fig:eqsat-example,
    language=Rust, 
    style=colouredRust, 
    caption={The example equality saturation program used in this chapter.}
]
// Enum declaration
define_language! {
    enum Expr {
        Add(Id, Id),
        Var(i64),
    }
}
// Rewrites
let rewrites = vec![
    rw!("(+ ?x ?y)" => "(+ ?y ?x)");
    rw!("(+ (+ ?x ?y) ?z) => "(+ ?x (+ ?y ?z))");
];
\end{lstlisting}

\section{Encoding E-graphs in Souffl\'e}

\subsection{Background}

Souffl\'e is a modern, efficient Datalog engine 
 that has wide applications in program analyses \citep{doop, souffle, souffle-interpreter}.
While sticking to the dogma of monotonicity, 
 Souffl\'e has been extended with a diverse range of extensions
 to both make it easier to program program analyses tasks
 and faster to run these tasks.
These extensions are amenable to the core theory of Datalog,
 e.g., monotonicity andsemi-na\"ive evalution.
 (suppose the user does not break the assumptions)\footnote{With the exception
 of termination guarantees of pure Datalog. 
 Similar to programs in many other practical Datalog engines, 
 Souffl\'e programs may not terminate
 since they are allowed to populate new values, which is useful in practice.}.
We sketch some of these extensions that are used in our encoding below:

\subsubsection*{Algebraic Data Types}
Souffl\'e supports algebraic data types (ADTs) as columns.
For example, the program below below declares 
 an Abstract Syntax Tree of the example in \autoref{fig:eqsat-example}
 in Souffl\'e
 and populates the term $v_1+v_2$ in relation $R$:
\begin{verbatim}
    .type Id = Add {x : Id, y : Id}
        | Var {n : number}
    .decl R(Id).
    R($Add($Var(1), $Var(2))).
\end{verbatim}

Internally, Souffl\'e keeps a record table for ADTs, 
 where each tuple has a unique reference id, 
 the branch id for its constructor, and
 the field values.
Therefore, 
 the encoding is very similar to the one used 
 in relational e-matching, with the difference being
 in relational e-matching, different branches of an AST
 is represented as different tables, 
 not different ids within the same table.
This encoding allows Souffl\'e to 
 perform efficient join over ADTs.
The reader may wonder 
 why we still use ADTs while we can 
 simulate the same features with 
 the relational encoding 
 \textit{a la} the relational \ematching paper.
In fact,
 we use both:
 ADTs are specifically used in a skolemizing fashion,
 i.e., we use ADTs as a handy way to creating new \eclass ids.
For example, \verb|$Add(x, y)| represents the ``natural'' \eclass id
 of the \enode with symbol \verb|Add| and children $x$ and $y$.
Other approaches to creating new \eclass ids include 
 using the hash of the \enodes, which we used for Rel.

\def\eqrel{\texttt{eqrel}}

\subsubsection*{Equivalence relations}
Equivalence relations are widely used 
 for different program analyses tasks, 
 such as Bitcoin user group analysis \citep{anonymity-bitcoin} 
 and points-to analyses \citep{multi-alaias-analysis,points-to-linear}.
While directly writing these equivalence relations as
 transitive, reflexive, symmetric rules are highly inefficient,
 data structures like union find \citep{unionfind} can 
 make reasoning about equivalence orders of magnititude faster.
Souffl\'e provides a built-in support for 
 equivalence relations named \eqrel. 
A relation declared as \eqrel{} will
 always satisfy the equivalence rules 
 and is implemented internally using union-find.
\eqrel{} is designed to be highly parallelizing, 
 and it compactly representes the equivalence relation
 in linear space, while it takes up to quadratic space
 to represent it directly.

\subsubsection*{Subsumptions}
Subsumption \citep{datalog-subsumption} is the idea that
 when one tuple is subsumed by another tuple semantically,
 it does not hurt to remove the subsumed tuples.
For example, 
 when computing the shortest paths between pairs of vertices in a graph,
 one may only care about the shortest paths. 
Consider the following Datalog program that computes the shortest path:
\begin{verbatim}
    p(x, y, c) :- e(x, y, c).
    p(x, y, c) :- p(x, z, cp), e(z, y, ce), c = cp + ce.
    sp(x, y, c) :- v(x), v(y), c = min c : p(x, y, c).
\end{verbatim}
This program will compute all possible paths between pairs of vertices,
 before aggregating over the paths to derive the shortest paths.
This is inefficient compared to the standard shortest path algorithms 
 like Dijkstra's algorithm.
Worst, when the graph contains (even positive) cycles, 
 these rules may not terminate, 
 because there are infinitely many paths.
Subsumption addresses this issue 
 by allowing the deletion of paths that are knwon to be not optimal,
 i.e., those non-shortest paths:
\begin{verbatim}
    sp(x, y, c) :- e(x, y, c).
    sp(x, y, c) :- sp(x, z, cp), e(z, y, ce), c = cp + ce.
    sp(x, y, c1) <= sp(x, y, c2) :- c1 >= c2.
\end{verbatim}
The last rule defines a partial order on
 \verb|sp| and says that tuple \verb|sp(x, y, c1)| 
 will be subsumed by tuple \verb|sp(x, y, c2)| if
 \verb|c1| is less than or equal to \verb|c2| 
 (note subsumption is a reflexive relation).
Operationally,
 the ``reduced set'' will be computed 
 after each iteration of evaluation according to
 the subsumptive rules.
\citet{datalog-subsumption} developed 
 a rigourous theory of subsumptions in Datalog
 and proved its soundness.
Finally,
 other approaches are proposed based on 
 semirings \citep{datalogo,datalogo-convergence}
 and lattices \citep{flix}.
For example, the Rel language,
 introduced in \autoref{section/rel},
 is based on the semiring approach.

In our encoding, we use subsumptions 
 to remove obsolete information.
For example,
 \eclasses are being constantly merged, updated, and canonicalized,
 which will cause \enodes to be canonicalized from time to time.
This leads to the existence of multiple representations of
 the same \enode, with only one being the canonical at any time.
Keeping these stale \enodes will explode the \egraph.
Instead,
 we can define a partial order over the \egraphs
 so that all stale \enodes are subsumed 
 by their canonical version and 
 let subsumptions to clean up the stale \enodes.
We will discuss this in details in \autoref{sec:subsumption}.
 
\subsubsection*{User-defined functors}
While Souffl\'e provides a rich set of primitive operators,
 it further provides the flexibility by allowing the users
 to bring their own functions, which Souffl\'e calls
 user-defined functors.
To declare a user-defined functor, 
 the user defines its implementation in a C++ program and
 link it during the execution of the Souffl\'e program.
Some of the encodings use the user-defined functors 
 to make \eqrel{} more flexible \citep{zucker-udf-1,zucker-udf-2}.
Compared to the standard usage, 
 we use user-defined functors in a rather wild way, 
 following \citet{zucker-udf-1} (see \autoref{sec:hack}).

\subsubsection*{Aggregations}
Finally, Souffl\'e supports stratified aggregations, 
 which is a standard extension to Datalog.
In other words, 
 Souffl\'e accepts programs where 
 aggregation operators like \texttt{max}, \texttt{min}, and \texttt{sum}
 does not transitively refer to themselves (i.e., are not recursive).
The stratification requirement is crucial to the soundness of the extension
 because it guarantees that the rules are monotonic.
Below is an example that does not satisfy the stratification:
\begin{verbatim}
    R(x) :- x = 1.
    R(c + 1) :- c = max x : R(x)
\end{verbatim}
Aftr the first iteration, the database $D_1$ will contain only $R(1)$. 
In the second iteration, because the second rule fires,
 the database $D_2$ will be $\{R(1), R(2)\}$.
However, in the third iteration,
 the application of the second rule to $D_2$ will yield
 $R(3)$, and $R(2)$ that used to exist in $D_2$ is now found nowhere,
 which breaks monotonicity.

That being said, there are Datalog programs that break monotonicity,
 yet are still (semantically) monotonic (e.g., one with subsumptions).
We use recursive aggregations 
 throughout in our encoding, because it is semantically clear that 
 \egraphs are growing in a monotonic way.
Souffl\'e does not support recursive aggregations by default,
 so we pass the \verb|--disable-transformers=SemanticChecker|
 flag to Souffl\'e to disable the semantic check.
By doing this, 
 we entered the dangerous land of Souffl\'e 
 since all the assumptions checked by the semantic checker
 could be violated.
This could also have performance implications:
each single aggregation is fully computed using linear scan every time 
 instead of incrementally maintained,
 since the design of Souffl\'e does not expect
 recursive use of aggregations.
When aggregations are stratified,
 this is fine because all the aggregations are ``one-shot'',
 while when aggregations are used recursively, 
 this means that the aggregations
 will require repeated linear scans of aggregated relations.
This can be prohibitively expensive, 
 and we mitigate this issue with more hacking into Souff\'e's internals.

\subsection{A Nai\"ve Encoding}\label{sec:naive}

% We start with a very nai\"ve encoding of \egraphs.
Our first encoding is inspired by the denotation of \egraphs:
 an \egraph represents a set of terms and a congruence relation over them.
We can use the relational representation in the relational \ematching paper
 to represent the set of terms, 
 and use \eqrel{} to represent the congruence relation over terms.
\begin{verbatim}
    .type Id <: number
    .decl add(I : Id, I : Id, id : Id)
    .decl var(x : number, c : Id)
    .decl eql(x : Id, y : Id) eqrel
    add(y, x, yx), eql(xy, yx) 
      :- add(x, y, xy), yx = ???.
    add(x, yz, x_yz), add(y, z, yz) 
      :- add(x, y, xy), add(xy, z, xy_z), 
         yz = ???, x_yz = ???.
\end{verbatim}
Here we are using integers to represent e-class ids, 
 but we run into an issue:
 we do not know how to refer to the \eclass id
 of (potentially) new \eclasses.
For example,
 in the commutativity rule,
 it is not obvious what value should we assign to \verb|yx|.
% The reader may be tempted to write the commutativity as
% \begin{verbatim}
%     add(y, x, xy) :- add(x, y, xy).
% \end{verbatim}
% to denote $x+y$ and $y+x$ has the same \eclass id.
% However, this is not correct.
One approach is to take the hash function of its children \eclass ids,
 yet it may lead to collision (with a relatively small probability).
Instead, we took inspiration from the skolemized chase \citep{bench-chase} and use ADTs 
 to represent the ``natural'' \eclass id of the \enode,
 e.g., the id of $x+y$ is \verb|$Add(x, y)|.
\begin{verbatim}
    .type Id = Add {x : Id, y : Id}
             | Var {n : number}
    .decl add(I : Id, I : Id, id : Id)
    .decl var(x : number, c : Id)
    .decl eql(x : Id, y : Id) eqrel
    add(y, x, yx), eql(xy, yx) 
      :- add(x, y, xy), yx = $Add(y, x).
    add(x, yz, x_yz), add(y, z, yz) 
      :- add(x, y, xy), add(xy, z, xy_z), 
         yz = $Add(y, z) x_yz = $Add(x, yz).
\end{verbatim}
The above program describes the way we perform rewrites in Souffl\'e,
 where the idea is general across the encodings presented in this section.

However, this is not a complete \egraph implementation yet.
First, it does not represent the whole term space, 
 which will miss potential rule firing.
For example, suppose the databse has \verb|{add(a, b, c1), add(c2, d, e), eql(c1, c2)}|,
 because \verb|c1| and \verb|c2| are equivalent, 
 the associativity rule should be fired.
However, the rewrite rules does not syntactically match.
There are two solutions in this na\"ve encoding.
First, we can modify the rewrite rules, e.g.,
 we can rewrite the associativity rule to be:
\begin{verbatim}
    add(x, yz, x_yz), add(y, z, yz) 
      :- add(x, y, xy1), eql(xy1, xy2), add(xy2, z, xy_z), 
         yz = $Add(y, z) x_yz = $Add(x, yz).
\end{verbatim}
Note that the \verb|eql| relation is quadratic in size,
 so this rewrite rule will be drastically slower than the original one.
Alternatively,
 it is also possible to simply populate the whole term space, with the following rules.
\begin{verbatim}
    add(x1, y, c) :- add(x, y, c), eql(x, x1).
    add(x, y1, c) :- add(x, y, c), eql(y, y1).
    add(x, y, c1) :- add(x, y, c), eql(c, c1).
    num(x, c1) :- num(x, c), eql(c, c1).
\end{verbatim}
As an \egraph can represent exponentially many terms,
 this could be even slower.
Finally, after fixing the above missed firing, there is one last missing piece:
 \verb|eql| is not a congruence relation yet.
For it to be congruent,
 the following rules need to be added (assuming our encoding populates the entire term space):
\begin{verbatim}
    eql(c1, c2) :- add(x, y, c1), add(x, y, c2).
    eql(c1, c2) :- num(x, c1), num(x, c2).
\end{verbatim}
If the term space is not explicitly represented,
 we could add one more indirection to our congruence rule 
 via the \verb|eql| relation as
 we did for rewrites:
\begin{verbatim}
    eql(c1, c2) :- add(x1, y1, c1), add(x2, y2, c2),
                   eql(x1, x2), eql(y1, y2).
\end{verbatim}

\subsection{An Encoding with the Leader Relation}\label{sec:leader}

The na\"ive encoding is not really an \egraph.
It is more like an explicit way of encoding the congruence relation
 and rewrites over it.
An \egraph is a particular data structure that 
 makes the congruence relation efficient.
To make the congruence relation highly efficient,
 \egraph aggressively canonicalizes its \enodes:
In a valid \egraph,
 only canonicalized \enodes and \eclass will exist,
 so there won't be two different representations of 
 semantically equivalent \enodes and \eclasses.
This enables efficient matching in \egraph, 
 since we only need to match on the canonical representation.
While in our na\"ive encoding, 
 we need to either populate all possible representations of an \enode,
 or we match with a layer of indirection.
Therefore, 
 a natural idea is to also do canonicalization in the Datalog encoding.

To canonicalize, we first need to pick a canonical id for each \eclass.
% There are several ways of doing it.
% The design choices we considered include using timestamps and hash values.
% Timestamps are hacky and hash functions may 
%  cause collisions\footnote{Nonetheless, we use hash functions in our Rel encoding,
%  given the probability of collision is very low.}.
Here, we pick the canonical id to be the min of all ids (converted from the pointer to the ADT) 
 in this \eclass,
 which we call the leader. 
The relation that maps an arbitrary id to its leader can be straightforwardly defined
 as follows:
\begin{verbatim}
    .decl leader(a : Id, b : Id)
    leader(a, as(b, Id)) :- 
        eql(a, a), // constraint a to be an e-class id
        b = min b1 : { eql(a, b), b1 = as(b, number) }.
\end{verbatim}

The leader relation has a similar purpose 
 as the \verb|find| operation of 
 the union-find data structure,
 as both return the canonical representation of an \eclass id
 and can be rather efficiently maintained 
 under updates to the congruence relations.
However, 
 the union-find data structure is significantly more efficiently,
 since it does not instantiate all the \verb|(id, canonical-id)|
 pairs, which the leader relation does.
Therefore,
 when an update to the congruence relation happens,
 the leader relation may update all the $O(N)$ pairs
 in worst case.
Note
 there are two intricacies to this statement.
First, in the encoding presented in this section,
 no tuples are updated in-place.
Rather, new tuples are populated and
 the old tuples will not be removed.
\autoref{sec:subsumption} will introduce a way 
 to delete old tuples via subsumption.
Second, the updates to the leader relation 
 is not immediately performed 
 when the congruence relation is updated.
Rather,
 the leader relation is re-computed iteration by iteration
 in a batched fashion.
This may amortize the cost of updating the relation.
Overall,
 the declarative nature of Datalog makes it more complicated
 to reason about the run-time behavior, 
 in particular the time complexity, of the leader relation.
That being said,
 the declarativeness makes reasoning about the correctness easier.

With the leader relation, 
 we populate canonicalized \enodes 
 for each \enode:
\begin{verbatim}
    add(x1, y1, c1) :- add(x, y, c), 
        leader(x, x1), leader(y, y1), leader(c, c1).
    num(x, c1) :- num(x, c), leader(c, c1).
\end{verbatim}
Compared to the na\"ive encoding,
 this does not populate the whole term space,
 but only a space that include all \enodes that are once canonical.
As a result,
 it may contain \enodes that are not necessarily canonical (but used to).
This means extra spaces are needed for these non-canonical \enodes,
 and redundant matching may be performed on them.
Moreover, the leader relation is monotonically computed,
 meaning that the leader relation may 
 record all the historical leaders of an \eclass id.
Yet this is still far less work than our na\"ive encoding, 
 where we represent every term explicitly.
In terms of the actual performance,
 this encoding is capable of saturate 
 the \egraph with initial expression $\sum_{i=1}^Nv_i$
 under AC rules for $N=5$ in 0.37 second
 and $N=6$ in two minutes, 
 while the na\"ive encoding does not terminate in three minutes.

As a final note,
 compared to the na\"ive encoding,
 this encoding is no longer stratified:
 \verb|leader| aggregaets over \verb|eql|
 and populates \verb|add|;
 \verb|add| is used in rewrite rules,
 which updates \verb|eql|.
Therefore, \verb|leader| can update the relation it aggregates over,
 which is not sound in general.
Starting at this section,
 all the encodings rely on the monotonicity of \egraphs to justify the soundness.

\subsection{Optimizing the leader relation with subsumptions}\label{sec:subsumption}

One of the inefficiencies of the encoding presented in \autoref{sec:leader} is 
 from the redundant \enodes and leader entries 
 that was once up-to-date (but no longer).
Ideally, one will want to get rid of these stale \enodes and leader entries,
 yet plain Datalog does not removal of tuples for the sake of monotonicity.
Fortunately,
 subsumption allows us to remove subsumed tuples given a partial order.
Particularly, 
 since we define the leader of an \eclass id to be the smallest id 
 that is equivalent to it,
 the partial order over \eclass ids can be straightforwardly given by $<$ 
 within the same equivalence class.
Therefore, the following rule can be added to remove stale leader entries 
 when a ``better'' leader is found:
\begin{verbatim}
    leader(x, y1) <= leader(x, y2) :-
        as(y1, number) <= as(y2, number).
\end{verbatim}
Similarly, to canonicalize \enodes:
\begin{verbatim}
    add(x1, y1, c1) <= add(x2, y2, c2) :-
        leader(x1, x2), leader(y1, y2), leader(c1, c2).
    var(x, c1) <= var(x, c2) :-
        leader(c1, c2).
\end{verbatim}

However, the first rule, which canonicalize \verb|add|, 
 is extremely slow in Souffl\'e due to poor query planning.
It will perform a cross product over the \verb|add|$\times$\verb|add|,
 which is not acceptable.
Therefore, we need to instead specify a manual query plan for this rule:
\begin{verbatim}
    add(x1, y1, c1) <= add(x2, y2, c2) :-
        leader(x1, x2), leader(y1, y2), leader(c1, c2).
        .plan 0:(1, 3, 4, 5, 2), 
              1:(1, 3, 4, 5, 2), 
              2:(1, 3, 4, 5, 2), 
              3:(1, 3, 4, 5, 2), 
              4:(1, 3, 4, 5, 2), 
              5:(1, 3, 4, 5, 2)
\end{verbatim}
The following query plan is specified:
\begin{verbatim}
                            Join
                      +-------+------+
                      |              |
                      |              |
                    Join       leader(c1, c2)
               +------+------+
               |             |
               |             |
             Join      leader(y1, y2)
        +-----+----+
        |          |
        |          |
add(x1, y1, c1)  leader(x1, x2)
\end{verbatim}
Since the leader relation is (almost) an bijection,
 this join plan can be executed in (almost) linear time.
These two rules decreases the runtime from two minutes 
 to 22 seconds for $N=6$ in the above benchmark, 
 yielding a 6$\times$ speedup.

Finally, as a side optimization, 
 so far we have been using \verb|eql(a, a)| 
 enumerate through \eclass ids.
It turns out Souffl\'e's \eqrel{} will 
 enumerate the (delta of the) \verb|eql| relation
 for this operation, which is super linear to
 the size of \eclass ids.
To get rid of this overhead,
 we explicitly represent all the ids:\footnote{
     Readers may be curious why we still keep the \texttt{eql} atom
     of leader computations.
     In fact, the author is curious as well---deleting it
     makes the output unsound. 
     The author speculates this is to make sure that
     \texttt{leader} is dependent on \texttt{eql}, 
     which Souffl\'e cannot infer otherwise.
     Alas, too many hacks.}
\begin{verbatim}
    .decl ids(a : Id)
    ids(x) :- add(_, _, x).
    ids(x) :- var(_, x).
    leader(a, as(b, Id)) :- 
        ids(a), eql(a, a), 
        b = min b1 : { eql(a, b), b1 = as(b, number) }.
\end{verbatim}
This makes sure enumerating ids will run linearly in the size of \eclass
 ids and further reduces the run time to 17 seconds.

\subsection{Efficient computation of leaders using reflections}\label{sec:hack}

With the subsumption-based optimiaztion in the last section,
 we are able to keep only canonicalized \enodes and \eclasses,
 which makes the rule rewriting even more efficient.
However, benchmarking the program from the last section
 shows that the majority of time is spent in computing the leader relation,
 even though we have made sure \eclass enumeration takes only linear time.
Therefore, our last optimization for the Souffl\'e encoding of \egraph
 will focus on rules that compute the leader relation.

Let us begin by revisiting the leader rules:
\begin{verbatim}
    leader(a, as(b, Id)) :- 
        ids(a), eql(a, a), 
        b = min b1 : { eql(a, b), b1 = as(b, number) }.
    leader(x, y1) <= leader(x, y2) :-
        as(y1, number) <= as(y2, number).
\end{verbatim}
The first rule is extremely slow.
Inspecting into the generated IR
 shows that for every \verb|a|, 
 Souffl\'e will enumerate through the \verb|eql| relation indexed by \verb|a|
 to find the smallest id,
 which is a linear operation.
Moreover,
 even though the smallest id stays the same within the same equivalence class,
 Souffl\'e does not know that.
As a result,
 an equivalence class of size $n$ will need to recompute \verb|min| $n$ times.
Therefore, rule can take up to quadratic time at each iteration.

To address the second issue, 
 I follow \citet{zucker-udf-1}, 
 reflecting the internals of \verb|eqrel| of Souffl\'e out
 to programs written in Souffl\'e.
Admittedly, this is very hacky and dangerous,
 but it gives us the last speedup for our Souffl\'e encoding.
To implement this optimization, 
 we first add support for the \verb|FIND| operation, 
 which finds the internal canonical representations
 of members of the \verb|eql| relation, to our program.
A user-defined functor called \verb|FIND| is declared
 in our Souffl\'e program,
 using Souffl\'e compiler to generate C++ code, 
 and text-replace each call to \verb|FIND| to an call 
 to the internal union-find data structure.

\verb|FIND| allows us to save work by
 only allowing the canonical id to perform aggregation,
 and any other id \verb|a| should instead derive its leader by consulting the leader
 of \verb|FIND(a)|.
This ensures that every \eclass will perform only one aggregation over its members:
\begin{verbatim}
    leader(a, as(b, Id)) :- 
        ids(a), eql(a, a), 
        a = FIND(a), b = min b1 : { eql(a, b), b1 = as(b, number) }.
    leader(a, b) :- 
        ids(a), eql(a, a), a != FIND(a), leader(FIND(a), b).
\end{verbatim}
This effectively makes the computation of the leader relation in each iteration
 linear in the size of ids,
 since every id will be enumerated only once by the \verb|ids| relation
 and once by the aggregation.

% it's interesting that Souffl\'e does not permit this in its API design,
% for monotonicity?

Finally, if the internals of Souffl\'e have already provided us 
 with a canonical representation,
 why would we even bother to compute leader at all?
\begin{verbatim}
    leader(a, FIND(a)) :- ids(a), eql(a, a).
    leader(x, y1) <= leader(x, y2) :-
        eql(y1, y2),
        y2 = FIND(y1).
\end{verbatim}

This is our ultimate encoding of \egraphs in Souffl\'e, being able to saturate 
 \(\sum_{i=1}^6 v_i\) under AC rules in under one second, 
 and \(\sum_{i=1}^7 v_i\) within 20 seconds, 
 which all other encodings presented in this section times out.

\section{Encoding E-graphs in Rel}\label{section/rel}

The Souffl\'e encoding of \egraphs is concise and efficient.
However, it relies on some of the critical features of Souffl\'e,
 such as subsumptions and built-in equivalence relations,
 without which the encoding will be orders of magnititude slower 
 (e.g., the na\"ive encoding in \autoref{sec:naive}).
Moreover, the design of the Souffl\'e encoding is also limited 
 by some of the restrictions Souffl\'e imposes.
For example,
 strict monotonicity means that tuples existing in the last iteration
 will stay here unless subsumption explicitly removed it.

In this section, we consider this same problem of encoding \egraphs in Datalog
 from a quite different spot in the design space.
Rel does not support subsumptions nor built-in equivalence relations,
 yet it eases general-purpose programming by sacrificing monotonicity.
Rel does not check for monotonicity during the compilation, 
 and the evaluation algorithm by default does not perform semi-na\"ive evaluation
 nor keep old tuples.
Instead, Rel iteratively applies the rules to the lastest database instance 
 to derive the input to the next iteration, 
 so if a tuple $t$ is computed at iteration $n-1$ but not at iteration $n$, 
 where the fixpoitn is reached, the resulting database instance will not contain $t$.
The oversimplified evaluation algorithm is as follow:
\begin{verbatim}
    def eval_rules(edb, rules):
        db = edb
        do
            db = apply_rules(rules, db)
        while db does not change
\end{verbatim}
This is a fundamental difference between Rel and Souffl\'e:
 in Souffl\'e, even if the rules are not monotonic,
 one has to explicitly use subsumptions to remove an old tuple.
The oversimplified evaluation algorithm of Souffl\'e is as follows:
\begin{verbatim}
    def eval_rules(edb, rules):
        db = edb
        do
            new_db = apply_rules(rules, db)
            db = db + new_db
        while delta does not change
\end{verbatim}
As we have seen, this can sometimes be a headache 
 because one need to explicitly remove obsolete tuples.
In comparison,
 Rel's non-monotonic semantics allows us to write iterative algorithms that are
 not monotonic (with regard to tuple inclusion) much easier.

Rel also has an expressive set of language features:
 relations can be defined in place using comprehension syntax,
 are easily composible via comma (,) operator (for cartesian product) 
 and semicolon (;) operator (for union),
 and can be used as arguments to higher-order functions like \verb|hash|;
 universal and existential quantifiers can be nested;
 and there are rich syntactic sugars for relational programming, e.g.,
 \verb|R[a]| means \verb|b: R(a, b)|.
% Such language features make Rel a relational programming language where
%  developers can build high-level applications with complicated business logic,
%  which is unusual as traditional database languages like SQL 
%  are believed to be low-level, non-composable, and syntactically cumbersome.
% Moreover, compared to standard Datalog, 
%  Rel gives up monotonicity for practicality,
%  as real-world applications are not necessarily monotonic 
%  (with regard to set inclusion).
This section will not attempt to cover all the features of Rel;
 instead, we will introduce each language feature of Rel as we use them.



\section{Miscellaneous}

thank Bernhard Scholz

thank Rel

thank Phil for his blog posts